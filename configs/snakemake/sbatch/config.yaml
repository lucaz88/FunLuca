# cluster: 
#   "sbatch --nodes 1 
#   --partition zen3_0512 --qos p71863_0512 
#   --time=00:59:00 
#   --mail-user=luca.zoccarato@boku.ac.at --mail-type=FAIL,END"
cluster: 
  sbatch
    --nodes={resources.nodes}
    --time={resources.time}
    --partition={resources.partition}
    --qos={resources.qos}
    --job-name={rule}-{wildcards}
    --parsable # Required to pass job IDs to scancel
    # --mem={resources.mem_mb}


default-resources:
  - nodes=1
  - partition="zen3_0512"
  - qos="p71863_0512"
  - time="00:59:00" #!!! job below 1h get allocated almost in RT
  # - mem_mb=6*input.size_mb
  # - disk_mb=max(2*input.size_mb, 10000)


# cores: # is overruled by Snakemake config file
#   88
jobs:
  1000
cluster-cancel: # kill submitted jobs when killing a snakemake run
  scancel

use-conda:
  True
conda-frontend:
  mamba
conda-prefix: # avoid duplication of envs but it's impossible to simultaneously fetch 2 envs from 2 different snakemake projects
  "~/VSC5_data/snakemake_envs/conda" 

use-singularity:
  True
singularity-prefix:
  "~/VSC5_data/snakemake_envs/singularity"

printshellcmds: 
  True
keep-going: 
  True
rerun-incomplete: 
  True
# keep-incomplete: # good for debugging
#   True